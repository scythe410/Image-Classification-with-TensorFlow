{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions with Complex Images (Local)\n",
    "\n",
    "> **THIS NOTEBOOK IS STILL INCOMPLETE**\n",
    "\n",
    "This aim is to train and optimize a CNN model to classify images of horses vs humans using TensorFlow locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to:\n",
    "\n",
    "1. Train a CNN model locally using TensorFlow\n",
    "2. Use the Horses or Humans dataset from TensorFlow Datasets\n",
    "3. Evaluate the model on test data\n",
    "4. Make predictions on individual images\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We'll train a neural network to classify images from the [Horses or Humans](https://www.tensorflow.org/datasets/catalog/horses_or_humans) dataset.\n",
    "\n",
    "This dataset contains 1283 images of resolution 300x300. We'll use 1027 images to train the network and 256 images to evaluate accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "# !pip install tensorflow tensorflow-datasets matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Disable progress bar for cleaner output\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)\n",
    "print('GPU Available:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 8\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading Horses or Humans dataset...\")\n",
    "datasets, info = tfds.load('horses_or_humans', with_info=True, as_supervised=True)\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(info)\n",
    "\n",
    "# Get train and test datasets\n",
    "train_dataset = datasets['train']\n",
    "test_dataset = datasets['test']\n",
    "\n",
    "print(f\"Training samples: {info.splits['train'].num_examples}\")\n",
    "print(f\"Test samples: {info.splits['test'].num_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and batch process the training dataset\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Prepare test dataset for evaluation\n",
    "test_dataset = test_dataset.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "plt.figure(figsize=(12, 8))\n",
    "class_names = ['Horse', 'Human']\n",
    "\n",
    "# Get a batch of images and labels\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(min(8, len(images))):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'{class_names[labels[i]]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Convolutional Neural Network\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 'horses' and 1 for 'humans'\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to save the best model\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_binary_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['binary_accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for visualization\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Collect some test samples\n",
    "for images, labels in test_dataset.take(1):\n",
    "    test_images.extend(images.numpy())\n",
    "    test_labels.extend(labels.numpy())\n",
    "\n",
    "# Convert to numpy arrays and take first 20 samples\n",
    "test_images = np.array(test_images[:20])\n",
    "test_labels = np.array(test_labels[:20])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Sample predictions (raw): {predictions[:5].flatten()}\")\n",
    "print(f\"Sample predicted classes: {predicted_classes[:5]}\")\n",
    "print(f\"Sample true labels: {test_labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(15, 12))\n",
    "class_names = ['Horse', 'Human']\n",
    "\n",
    "for i in range(min(20, len(test_images))):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(test_images[i])\n",
    "    \n",
    "    predicted_class = predicted_classes[i]\n",
    "    true_class = test_labels[i]\n",
    "    confidence = predictions[i][0]\n",
    "    \n",
    "    # Color: green if correct, red if incorrect\n",
    "    color = 'green' if predicted_class == true_class else 'red'\n",
    "    \n",
    "    plt.title(f'Pred: {class_names[predicted_class]}\\nTrue: {class_names[true_class]}\\nConf: {confidence:.3f}', \n",
    "              color=color, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_classes == test_labels)\n",
    "print(f\"\\nAccuracy on sample: {accuracy:.3f} ({np.sum(predicted_classes == test_labels)}/{len(test_labels)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# Generate timestamp for unique filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save in native Keras format (recommended)\n",
    "keras_path = f'horses_vs_humans_model_{timestamp}.keras'\n",
    "model.save(keras_path)\n",
    "print(f\"Model saved to: {keras_path}\")\n",
    "\n",
    "# Save as TensorFlow SavedModel format (optional, but useful for deployment)\n",
    "saved_model_path = f'horses_vs_humans_model_{timestamp}_savedmodel'\n",
    "tf.saved_model.save(model, saved_model_path)\n",
    "print(f\"Model also saved in SavedModel format to: {saved_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully:\n",
    "\n",
    "1. ✅ Loaded the Horses or Humans dataset from TensorFlow Datasets\n",
    "2. ✅ Built and trained a CNN model locally\n",
    "3. ✅ Evaluated the model on test data\n",
    "4. ✅ Visualized training progress and predictions\n",
    "5. ✅ Saved the trained model for future use\n",
    "6. ✅ Provided a function to make predictions on new images\n",
    "\n",
    "The model achieves good accuracy in distinguishing between horses and humans in images. You can now use this model to classify new images or further improve it with techniques like data augmentation, transfer learning, or hyperparameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
