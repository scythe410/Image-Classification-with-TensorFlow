{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ca01fa",
   "metadata": {},
   "source": [
    "# A neural network to classify images of clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03628bfe",
   "metadata": {},
   "source": [
    "We're using a dataset called 'Fashion MNIST'. GitHub: https://github.com/zalandoresearch/fashion-mnist.\n",
    "\n",
    "This dataset contains 60,000 training images and 10,000 testing images. Each image is a 28x28px grayscale image of a fashion item, associated with a label from 10 classes. The task is to predict the class of the image (e.g. t-shirt , dress, etc.). Each image has a resolution of 28x28 pixels and is grayscale (1 channel). The grayscale values range from 0 to 255, where 0 represents black and 255 represents white.\n",
    "\n",
    "| Label | Item |\n",
    "|-------|------|\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "<p></p>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <img src=\"mnist.png\" width=400px alt=\"mnist dataset image\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"mnist.gif\" width=600px alt=\"mnist classes\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbda46",
   "metadata": {},
   "source": [
    "tfds.load loads\n",
    "\n",
    "`split` specifies which splits of the dataset is to be loaded. You set as_supervised to True to ensure that the loaded tf.data.Dataset will have a 2-tuple structure (input, label).\n",
    "\n",
    "`ds_train` and `ds_test` are of type `tf.data.Dataset`. `ds_train` has 60,000 images which will be used for training the model. `ds_test` has 10,000 images which will be used for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "024db661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define, load and configure data\n",
    "(ds_train, ds_test), info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "143fdbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n",
      "Number of training examples: 60000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "header = info.features['label'].num_classes\n",
    "print(f\"Number of classes: {header}\")\n",
    "print(f\"Number of training examples: {info.splits['train'].num_examples}\")\n",
    "print(f\"Number of test examples: {info.splits['test'].num_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbc9bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization -> 0 227\n"
     ]
    }
   ],
   "source": [
    "# Minium and maximum values before normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"Before normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715494da",
   "metadata": {},
   "source": [
    "> `Batch size` refers to the number of training examples utilized in one iteration.\n",
    "\n",
    "We'll be normalizing the data to exist between 0 and 1.\n",
    "\n",
    "code given below uses the `map()` function of `tf.data.Dataset` to apply the normalization to images in `ds_train` and `ds_test`. Since the pixel values are of type `tf.uint8`, the `tf.cast` function is used to convert them to `tf.float32` and then divide by 255.0. The dataset is also converted into batches by calling the `batch()` method with BATCH_SIZE as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "323df650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d006fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and batch process the dataset\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)\n",
    "ds_test = ds_test.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bee7eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization -> 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Min and max values of the batch after normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"After normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538b2ca",
   "metadata": {},
   "source": [
    "## Design, Compile and Train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
