{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ca01fa",
   "metadata": {},
   "source": [
    "# A neural network to classify images of clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03628bfe",
   "metadata": {},
   "source": [
    "We're using a dataset called 'Fashion MNIST'. GitHub: https://github.com/zalandoresearch/fashion-mnist.\n",
    "\n",
    "This dataset contains 60,000 training images and 10,000 testing images. Each image is a 28x28px grayscale image of a fashion item, associated with a label from 10 classes. The task is to predict the class of the image (e.g. t-shirt , dress, etc.). Each image has a resolution of 28x28 pixels and is grayscale (1 channel). The grayscale values range from 0 to 255, where 0 represents black and 255 represents white.\n",
    "\n",
    "| Label | Item |\n",
    "|-------|------|\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "<p></p>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"margin-right: 20px;\">\n",
    "        <img src=\"mnist.png\" width=400px alt=\"mnist dataset image\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"mnist.gif\" width=600px alt=\"mnist classes\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e6c73",
   "metadata": {},
   "source": [
    "## Loading data and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbda46",
   "metadata": {},
   "source": [
    "> `tfds.load` loads the data.\n",
    "\n",
    "> `split` specifies which splits of the dataset is to be loaded. You set as_supervised to True to ensure that the loaded tf.data.Dataset will have a 2-tuple structure (input, label).\n",
    "\n",
    "> `ds_train` and `ds_test` are of type `tf.data.Dataset`. `ds_train` has 60,000 images which will be used for training the model. `ds_test` has 10,000 images which will be used for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024db661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define, load and configure data\n",
    "(ds_train, ds_test), info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = info.features['label'].num_classes\n",
    "print(f\"Number of classes: {header}\")\n",
    "print(f\"Number of training examples: {info.splits['train'].num_examples}\")\n",
    "print(f\"Number of test examples: {info.splits['test'].num_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minium and maximum values before normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"Before normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715494da",
   "metadata": {},
   "source": [
    "> `Batch size` refers to the number of training examples utilized in one iteration.\n",
    "\n",
    "We'll be normalizing the data to exist between 0 and 1.\n",
    "\n",
    "code given below uses the `map()` function of `tf.data.Dataset` to apply the normalization to images in `ds_train` and `ds_test`. Since the pixel values are of type `tf.uint8`, the `tf.cast` function is used to convert them to `tf.float32` and then divide by 255.0. The dataset is also converted into batches by calling the `batch()` method with BATCH_SIZE as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323df650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d006fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and batch process the dataset\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)\n",
    "ds_test = ds_test.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min and max values of the batch after normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"After normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538b2ca",
   "metadata": {},
   "source": [
    "## Design, Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa298aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4a0e6",
   "metadata": {},
   "source": [
    "0. Sequential\n",
    "\n",
    "- This is the default mode. It means that the model will process the input data in a sequential manner, i.e., one sample at a time. This is the most common mode and is suitable for most use cases.\n",
    "\n",
    "\n",
    "1. Flatten Layer\n",
    "\n",
    "- Converts the 2D image array (28x28 pixels) into a 1D array (784 pixels)\n",
    "- No parameters to learn, just reshapes the data\n",
    "- Input: (28, 28) → Output: (784)\n",
    "\n",
    "2. Dense (addds a layer of neurons) Hidden Layer\n",
    "- 64 neurons in this hidden layer\n",
    "- ReLU activation function (Rectified Linear Unit)\n",
    "- Takes flattened input (784) and learns patterns\n",
    "- Parameters: 784 * 64 + 64 = 50,240 (weights + biases)\n",
    "\n",
    "3. Output Layer\n",
    "- 10 neurons (one for each clothing class)\n",
    "- Softmax activation for probability distribution\n",
    "- Parameters: 64 * 10 + 10 = 650 (weights + biases)\n",
    "\n",
    "Each layer of neurons needs an activation function to decide if a neuron should be activated or not. There are lots of options, but this lab uses the following ones.\n",
    "- `Relu` effectively means if X>0 return X, else return 0. It passes values 0 or greater to the next layer in the network.\n",
    "- `Softmax` takes a set of values, and effectively picks the biggest one so you don't have to sort to find the largest value. For example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it returns [0,0,0,0,1,0,0,0,0].\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"network_1.svg\" width=\"600px\" alt=\"\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0d725",
   "metadata": {},
   "source": [
    "The network architecture consists of:\n",
    "- Input: 28x28 grayscale image\n",
    "- Flatten → Dense(64) → Dense(10)\n",
    "- Total trainable parameters: 50,890\n",
    "\n",
    "Output is a probability distribution across 10 clothing classes:\n",
    "- T-shirt/top, Trouser, Pullover, Dress, Coat etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e102a",
   "metadata": {},
   "source": [
    "## Compilation\n",
    "\n",
    "The goal is for the model to figure out the relationship between the training data and its labels. Once training is complete, you want your model to see fresh images of clothing that resembles your training data and make predictions about what class of clothing they belong to.\n",
    "\n",
    "> `Optimizer` is an algorithm that modifies the attributes of the neural network like weights and learning rate. This helps in reducing the loss and improving accuracy.\n",
    "\n",
    "> `Loss` indicates the model's performance by a number. If the model is performing better, loss will be a smaller number. Otherwise loss will be a larger number.\n",
    "\n",
    "> `Metrics` parameter allows TensorFlow to report on the accuracy of the training after each epoch by checking the predicted results against the known answers(labels). It basically reports back on how effectively the training is progressing. For 0.9053 means the models is 90.53% accurate.\n",
    "\n",
    "Model.fit will train the model for a fixed number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.fit(ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21d47b",
   "metadata": {},
   "source": [
    "## Evaluating models's performance on unseen data\n",
    "\n",
    "model.evaluate, pass in the test set, and it reports back the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b207f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527db52",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "Model progress can be saved during and after training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. We will save and load the model now. \n",
    "\n",
    "The above code shows how you can save the model in two different formats and load the saved model back. You can choose any format according to your use case. At the end of the output you will see two sets of model summaries. The first one shows the summary after the model is saved in the SavedModel format. The second one shows the summary after the model is saved in the h5 format.\n",
    "\n",
    "Both model summaries are identical since we are effectively saving the same model in two different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402679e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a Keras model using .keras format\n",
    "model.save('saved_model.keras') \n",
    "\n",
    "# Load the model using custom_objects to handle the custom activation function\n",
    "new_model = tf.keras.models.load_model('saved_model.keras', custom_objects={'softmax_v2': tf.keras.activations.softmax})\n",
    "\n",
    "# Summary of loaded SavedModel\n",
    "new_model.summary()\n",
    "\n",
    "# Save the entire model to a keras file.\n",
    "model.save('my_model.keras')\n",
    "\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model_keras = tf.keras.models.load_model('my_model.keras', custom_objects={'softmax_v2': tf.keras.activations.softmax})\n",
    "\n",
    "# Summary of loaded keras model\n",
    "new_model_keras.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
